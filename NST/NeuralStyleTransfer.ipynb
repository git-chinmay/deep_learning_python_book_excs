{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65c4169f",
   "metadata": {},
   "source": [
    "## Neural Style Transfer using Keras\n",
    "\n",
    "NST can be implmented using any pretrained convnet. Here we will use the VGG19 network.\n",
    "\n",
    "NOTE: What this technique achieves is merely a form of image retexturing or texture trasnfer. It works best with style refernce images with strong textures. and with content target that dont require high level of details to recognize.\n",
    "\n",
    "This algorithm is closer to classical signal processing that to AI, so dont expect it to work like magic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa88df3",
   "metadata": {},
   "source": [
    "### Defining initial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "418a2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Path of the img imput files\n",
    "target_image_path = './img/portrait.png'\n",
    "style_reference_image_path = './img/transfer_style_reference.png'\n",
    "\n",
    "# Dimension of the generated picture\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = 400\n",
    "img_width = int(width * img_height / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fbf1ee2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283, 427, 265)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width, height, img_width"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ec9ef9",
   "metadata": {},
   "source": [
    "### Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3906e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "38386f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c43d1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    \"\"\" Zero centering by removing the mean pixel value from ImageNet.\n",
    "        This reverses a transformation done by vgg19.preprocess_input \"\"\"\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # Convert images from BGR to RGB(Part of vgg19 reversal)\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7a045f",
   "metadata": {},
   "source": [
    "### Loading the pretrained VGG19 network and applying it to the three images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e817ec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27138309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded.\n"
     ]
    }
   ],
   "source": [
    "target_image = K.constant(preprocess_image(target_image_path))\n",
    "style_reference_image = K.constant(preprocess_image(style_reference_image_path))\n",
    "combination_image = K.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "# Combining three images into a single batch\n",
    "input_tensor = K.concatenate([target_image, style_reference_image, combination_image], axis=0)\n",
    "\n",
    "# Build the VGG19 network with the batch of three images as input. The model will be laoded with pretrained ImageNet weights\n",
    "model = vgg19.VGG19(input_tensor=input_tensor, weights='imagenet', include_top=False)\n",
    "print('Model Loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de4acb7",
   "metadata": {},
   "source": [
    "### Content Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7a3fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination -  base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7d228e",
   "metadata": {},
   "source": [
    "### Style Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3afbb68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0,1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    s = gram_matrix(style)\n",
    "    c = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return K.sum(K.square(s-c)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a87a88",
   "metadata": {},
   "source": [
    "### Total variation loss\n",
    "\n",
    "With the above 2 losses we are adding 3rd loss total variation loss which opeartes on the pixels of the generated combination image. It encourages spatial continuity in the generated image, thus avioding overly pixalated results. We can interprete as a regulisation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4ccbeffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = K.square(x[:, :img_height - 1, :img_width - 1, :] - x[:, 1:, :img_width - 1, :])\n",
    "    b = K.square(x[:, :img_height - 1, :img_width - 1, :] - x[:, :img_height - 1, 1:, :])\n",
    "    return  K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1408705",
   "metadata": {},
   "source": [
    "### Defining final loss we will minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66f6db91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dinctinary that maps layer names to activation tensors\n",
    "output_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "content_layer = 'block5_conv2' #For content loss\n",
    "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1'] # FOr style loss\n",
    "\n",
    "# Weights in the weighted average of the loss components\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.25\n",
    "\n",
    "## Adds the content loss\n",
    "# Defining the loss by adding all components to this scalar variable\n",
    "loss = K.variable(0.)\n",
    "layer_features = output_dict[content_layer]\n",
    "target_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss = loss + content_weight * content_loss(target_image_features, combination_features)\n",
    "\n",
    "# Add a style loss component for each target layer\n",
    "for layer_name in style_layers:\n",
    "    layers_features = output_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss = loss + (style_weight / len(style_layers)) * sl\n",
    "    \n",
    "# Add the total variation loss\n",
    "loss = loss + total_variation_weight * total_variation_loss(combination_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420ca17f",
   "metadata": {},
   "source": [
    "### Setting up the gradient-descent process\n",
    "\n",
    "Computing loss and Gradient process seprately will be very slow as a lot of redundant process will run in between them hence we will setup a Python class named Evaluator that computes both the loss value and gradient value at once returns the loss when called the first time and caches the gradient for the next call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbc7b551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the gradients of the generated image with regard to the loss\n",
    "grads = K.gradients(loss, combination_image)[0]\n",
    "\n",
    "# Function to fetch the values of the current loss and the current gradients\n",
    "fetch_loss_and_grads = K.function([combination_image], [loss, grads])\n",
    "\n",
    "class Evaluator(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_value = None\n",
    "        \n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "    \n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae924de",
   "metadata": {},
   "source": [
    "### Style transfer loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ddea36c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b9b82d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iterations: 0\n",
      "Current loss value: 123301.0546875\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_0.png\n",
      "Iteration 0 completed in 122.82134366035461.\n",
      "Start of iterations: 1\n",
      "Current loss value: 123296.71875\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_1.png\n",
      "Iteration 1 completed in 129.85703492164612.\n",
      "Start of iterations: 2\n",
      "Current loss value: 123293.453125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_2.png\n",
      "Iteration 2 completed in 142.89585065841675.\n",
      "Start of iterations: 3\n",
      "Current loss value: 123291.0859375\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_3.png\n",
      "Iteration 3 completed in 138.08231687545776.\n",
      "Start of iterations: 4\n",
      "Current loss value: 123289.1484375\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_4.png\n",
      "Iteration 4 completed in 133.66913509368896.\n",
      "Start of iterations: 5\n",
      "Current loss value: 123288.2109375\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_5.png\n",
      "Iteration 5 completed in 146.11634063720703.\n",
      "Start of iterations: 6\n",
      "Current loss value: 123285.75\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_6.png\n",
      "Iteration 6 completed in 177.8690128326416.\n",
      "Start of iterations: 7\n",
      "Current loss value: 123283.4453125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_7.png\n",
      "Iteration 7 completed in 195.8683295249939.\n",
      "Start of iterations: 8\n",
      "Current loss value: 123281.1953125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_8.png\n",
      "Iteration 8 completed in 188.22079062461853.\n",
      "Start of iterations: 9\n",
      "Current loss value: 123279.140625\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_9.png\n",
      "Iteration 9 completed in 190.612943649292.\n",
      "Start of iterations: 10\n",
      "Current loss value: 123276.734375\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_10.png\n",
      "Iteration 10 completed in 179.44812679290771.\n",
      "Start of iterations: 11\n",
      "Current loss value: 123274.7421875\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_11.png\n",
      "Iteration 11 completed in 171.41353964805603.\n",
      "Start of iterations: 12\n",
      "Current loss value: 123273.03125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_12.png\n",
      "Iteration 12 completed in 169.54394817352295.\n",
      "Start of iterations: 13\n",
      "Current loss value: 123271.1796875\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_13.png\n",
      "Iteration 13 completed in 171.30753231048584.\n",
      "Start of iterations: 14\n",
      "Current loss value: 123269.3125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_14.png\n",
      "Iteration 14 completed in 169.85842537879944.\n",
      "Start of iterations: 15\n",
      "Current loss value: 123267.6171875\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_15.png\n",
      "Iteration 15 completed in 163.20494079589844.\n",
      "Start of iterations: 16\n",
      "Current loss value: 123265.0859375\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_16.png\n",
      "Iteration 16 completed in 128.68278408050537.\n",
      "Start of iterations: 17\n",
      "Current loss value: 123262.828125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_17.png\n",
      "Iteration 17 completed in 207.05535364151.\n",
      "Start of iterations: 18\n",
      "Current loss value: 123260.3671875\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_18.png\n",
      "Iteration 18 completed in 128.04321837425232.\n",
      "Start of iterations: 19\n",
      "Current loss value: 123258.03125\n",
      "Image saved as :./img/generated_img/my_result_at_iteration_19.png\n",
      "Iteration 19 completed in 123.09400534629822.\n"
     ]
    }
   ],
   "source": [
    "result_prefix = 'my_result'\n",
    "iterations = 20\n",
    "\n",
    "x = preprocess_image(target_image_path)\n",
    "# Need to flatten bcz fmin_l_bfgs_b can works on flattened image\n",
    "x = x.flatten()\n",
    "\n",
    "# Run L-BFGS optimizations over the pixels of the generated image to minimize the style loss.\n",
    "# We have to pass the function that computes the loss ad the function that computs the gradients as two separate arguments\n",
    "\n",
    "for i in range(iterations):\n",
    "    print(f\"Start of iterations: {i}\")\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x, fprime=evaluator.grads, maxfun=20)\n",
    "    print(f\"Current loss value: {min_val}\")\n",
    "    img = x.copy().reshape((img_height, img_width, 3))\n",
    "    img = deprocess_image(img)\n",
    "    fname = f\"./img/generated_img/{result_prefix}_at_iteration_{i}.png\"\n",
    "    plt.imsave(fname, img)\n",
    "    print(f\"Image saved as :{fname}\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Iteration {i} completed in {end_time - start_time}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b4bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
